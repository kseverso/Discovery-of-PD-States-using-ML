{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Motor Assessments\n",
    "In this notebook we will analyze some aspects of the non-motor variables, measurements done in PPMI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# All non-motor test sheets (what is there in each one), is described on page 8 of the curation_summary document\n",
    "# In this notebook we will look at each file in the full dataset related to non-motor tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ### PUT PATH TO DATA HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benton Judgement of Line Orientation\n",
    "The Benton Judegment of Line Orientation test measures a person's ability to match the angle and orientation of lines in space. Subjects are asked to match two angled lines to a set of 11 lines that are arranged in a semicircle and separated 18 degrees from each other. The complete test has 30 items. \n",
    "That is why we have 30 columns for BJLOT<num> where num=1 to 30\n",
    "But certain columns only occur on certain visits\n",
    "It seems like on certain days only a few lines in the orientation were tested on. And on other days some other lines.\n",
    "\n",
    "There is `JLO_TOTRAW` variable which is the sum of the scores (1 for correct and 0 for incorrect) on a particular visit.\n",
    "On taking a closer look. Some visits do odd number of lines, some do even. Which means effectively everytime only half of them are done. We will look at the stats related to this.\n",
    "The details on which visit has odd items and which has even read from Pg 67 in the PPMI_Protocol document.\n",
    "\n",
    "`JLO_TOTCALC` scales the raw score and gives how well a person did out of 30 - which is the standard for the test. This will be an important measure for our purposes.\n",
    "\n",
    "`DVS_JLO_MSSA` gives `JLO_TOTRAW` + `COMM` but not sure when `COMM` appears. It is rare in the CSV file.\n",
    "\n",
    "`DVS_JLO_MSSAE` seems some kind of error or a floating point representation of the `DVS_JLO_MSSA` column. Didn't find anything in the document related to this yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Benton_Judgment_of_Line_Orientation.csv\")\n",
    "df_1 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_1))\n",
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total records (rows):\",len(df_1))\n",
    "# Looks like a few patients did not do the BL visit\n",
    "print(\"Number of records for baseline visit:\",len(df_1[df_1.EVENT_ID==\"BL\"]))\n",
    "print(\"Unique patients:\", len(df_1.PATNO.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to show the number of visits done by the patients - Like how many people did 7 visits, 8 visits and so on\n",
    "# We do this by grouping PATNO\n",
    "df_1.groupby(['PATNO']).PATNO.count()\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.hist(df_1.groupby(['PATNO']).PATNO.count(),bins=range(0,11))\n",
    "plt.xlabel('Number of visits')\n",
    "plt.ylabel('Number of subjects')\n",
    "\n",
    "# So about 250 subjects have done 6 visits (these are across months). These patients can be monitored for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_series = df_1.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "\n",
    "\n",
    "events_series.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of age\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.hist(df_1['AGE_ASSESS_JLO'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of scores for TOTCALC\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.hist(df_1['JLO_TOTCALC'].dropna().astype(int), bins=np.arange(0,32)-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add graphs to show which visits have which benton test done. But it is also in the PDF so we will do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are reasons given for some of them and for some the other columns have indicators but still the total is \n",
    "# missing. Can discard these entries.\n",
    "df_1[df_1['JLO_TOTCALC'].isnull()].PATNO.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epworth Sleepiness Scale\n",
    "The questionnaire asks the subject to rate his or her probability of falling asleep on a scale of increasing probability from 0 to 3 for eight different situations that most people engage in during their daily lives, though not necessarily every day\n",
    "\n",
    "Can look at non-motor03 in the curated dataset to see the activities for each column. 3 is more sleepy, 1 is less sleepy and so on. Its a scale of 0-3.\n",
    "\n",
    "`PTCGBOTH` variable might be for Patient-Care giver-Both (1-2-3 values respectively). The curated one has a column that asks who reported the result. So this most likely means the same. Doesn't seem to be that important for our purposes.\n",
    "\n",
    "There isn't any aggregation across the sleepiness scores. They are all individual depending on certain times in the day and the activity being done by the patient. From overall analysis all of these columns (prefixed with ESS) would be important for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Epworth_Sleepiness_Scale.csv\")\n",
    "df_2 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_2))\n",
    "df_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do graphs similar to the ones for Benton\n",
    "# Plot to show the number of visits done by the patients - Like how many people did 7 visits, 8 visits and so on\n",
    "# We do this by grouping PATNO\n",
    "df_2.groupby(['PATNO']).PATNO.count()\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.hist(df_2.groupby(['PATNO']).PATNO.count(), bins=range(0,13))\n",
    "plt.xlabel('Number of visits')\n",
    "plt.ylabel('Number of subjects')\n",
    "\n",
    "# Here number of visits done are pretty consistent. That means we would need to consider more patients, but some\n",
    "# of them did certain visits, others did some others. Alignment will be an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_series_2 = df_2.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_2)\n",
    "\n",
    "events_series_2.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geriatric Depression Scale (GDS-15)\n",
    "The Geriatric Depression Scale (GDS) is a 30-item self-report assessment used to identify depression in the elderly. We only take 15 of these. Can look at their full form in non-motor04 file from curated dataset.\n",
    "\n",
    "They are all yes/no type of questions. 1 means yes and 0 means no. All the GDS columns would prove useful as a feature. For this and ESS, a single concatenated encoding vector could be used.\n",
    "\n",
    "There is no aggregate score available in the full dataset file. `F_STATUS` appears with only 4 rows having 'S' and rest all having 'V', not sure what it stands for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Geriatric_Depression_Scale__Short_.csv\")\n",
    "df_3 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_3))\n",
    "df_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do similar graphs for this too due to the similarity in structure in all these tables\n",
    "# Plot to show the number of visits done by the patients - Like how many people did 7 visits, 8 visits and so on\n",
    "# We do this by grouping PATNO\n",
    "df_3.groupby(['PATNO']).PATNO.count()\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.hist(df_3.groupby(['PATNO']).PATNO.count(), bins=np.arange(0,12)-0.5)\n",
    "plt.xlabel('Number of visits')\n",
    "plt.ylabel('Number of subjects')\n",
    "\n",
    "# Again there seems to be an even spread but falls off after 8, so we can skip those patients or not take\n",
    "# their final few visits into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_series_3 = df_3.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_3)\n",
    "\n",
    "events_series_3.plot.bar()\n",
    "\n",
    "# Like ESS seems to fall off after the 4th visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopkins Verbal Learning Test – Revised\n",
    "HVLT - A new test of verbal learning and memory, the Hopkins Verbal Learning Test, was developed. The test consists of three trials of free-recall of a 12-item, semantically categorized list, followed by yes/no recognition. The revised might have some additional things.\n",
    "\n",
    "The full forms for our column headers can be found in curated non-motor05 file. All the DVT columns in the full dataset are the dervied values and hence are important features for the model. `HVLTRSN` is the booklet version used for the test.\n",
    "\n",
    "It also looks like a higher value for all these tests is better. Which can give a high score overall. We should probably look to use the derived scores as features, since those encode the most important part of the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Hopkins_Verbal_Learning_Test.csv\")\n",
    "df_4 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_4))\n",
    "df_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the different versions and which one was used the most\n",
    "\n",
    "# df_4.HVLTVRSN.min()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_4.HVLTVRSN.dropna(), bins=np.arange(0,7)-0.5)\n",
    "plt.xlabel('Test Booklet Version')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "# So we can use just the records for version 1 and 2. Or we can take all since the metrics stay the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution of the derived scores across subjects and visits\n",
    "# df_4.DVT_RECOG_DISC_INDEX.min()\n",
    "\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(df_4.DVT_TOTAL_RECALL.dropna(), bins=np.arange(20,82)-0.5)\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('DVT_TOTAL_RECALL')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(df_4.DVT_DELAYED_RECALL.dropna(), bins=np.arange(20,82)-0.5)\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('DVT_DELAYED_RECALL')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(df_4.DVT_RETENTION.dropna(), bins=np.arange(20,82)-0.5)\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('DVT_RETENTION')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(df_4.DVT_RECOG_DISC_INDEX.dropna(), bins=np.arange(20,82)-0.5)\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('DVT_RECOG_DISC_INDEX')\n",
    "\n",
    "# Scores for most of these except the Recall test lies between 50-60; but overall a large chunk between 40 and 60 for\n",
    "# all of the derived scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_series_4 = df_4.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_4)\n",
    "# print(events_series.axes)\n",
    "# print(type(events_series.axes))\n",
    "# print(events_series.values)\n",
    "\n",
    "events_series_4.plot.bar()\n",
    "# Similar to others, gradual drop after a peek at V04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter Number Sequencing\n",
    "This is another neuropsychological test done on certain visits. Participants must recall a series of numbers in increasing order and letters in alphabetical order. 1 is correct and 0 is incorrect for each. There are 7 trials and two parts to each. \n",
    "\n",
    "`LNS_TOTRAW`(LNS-Sum Questions 1-7) and `DVS_LNS` (Derived-LNS Scaled Score) seem to be the important metrics we should add to the feature test from this test. Or only the derived one should also work. Not sure what calculation goes into the derived score, at some points values have increased and at some decreased from the TOTRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Letter_-_Number_Sequencing__PD_.csv\")\n",
    "df_5 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_5))\n",
    "df_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution of the derived scores across subjects and visits\n",
    "# df_5.DVS_LNS.max()\n",
    "\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(2,1,1)\n",
    "plt.hist(df_5.LNS_TOTRAW.dropna(), bins=np.arange(0,22)-0.5)\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('LNS_TOTRAW')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.hist(df_5.DVS_LNS.dropna(), bins=np.arange(0,22)-0.5)\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('DVS_LNS')\n",
    "\n",
    "# Look like Gaussians which is expected on any test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_series_5 = df_5.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_5)\n",
    "# print(events_series.axes)\n",
    "# print(type(events_series.axes))\n",
    "# print(events_series.values)\n",
    "\n",
    "events_series_5.plot.bar()\n",
    "# Again we see the same trend. Seems to be consistent across all the non-motor tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montreal Cognitive Assessment (MoCA)\n",
    "The Montreal Cognitive Assessment (MoCA) is a widely used screening assessment for detecting cognitive impairment. The details and also the column headers can be seen in curated non-motor07 file. 27 different tests are given to the subjects. The specific tests are listed in the curated file.\n",
    "\n",
    "`MCATOT` is the one that is the epitome of this sheet. Should add to the feature set. `F_STATUS` is there in this file too but still not sure what it stands for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Montreal_Cognitive_Assessment__MoCA_.csv\")\n",
    "df_6 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_5))\n",
    "df_6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of total scores\n",
    "# df_6.MCATOT.max()\n",
    "\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.hist(df_6.MCATOT.dropna(), bins=np.arange(0,32)-0.5)\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('MCATOT')\n",
    "\n",
    "# Everyone has a pretty high score on this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_6 = df_6.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_6)\n",
    "# print(events_series.axes)\n",
    "# print(type(events_series.axes))\n",
    "# print(events_series.values)\n",
    "\n",
    "events_series_6.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Olfactory Testing (UPSIT)\n",
    "The University of Pennsylvania Smell Identification Test (UPSIT) is a test that is commercially available for smell identification to test the function of an individual's olfactory system.\n",
    "\n",
    "Response columns have the thing they were actually told to smell and then whether they got it correct or not is in another column. Only the `TOTAL_CORRECT` seems to have some kind of signal related to this test. The percentage column I'm not sure about. It seems off or don't seem to get the calculation they have used there.\n",
    "\n",
    "Surprisingly this file doesn't have which visit happened on which visit. We would have to align using the date.\n",
    "\n",
    "`non-motor15` file has this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Olfactory_UPSIT.csv\")\n",
    "df_7 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_7))\n",
    "df_7.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the total scores for this test\n",
    "# df_7.TOTAL_CORRECT.max()\n",
    "\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.hist(df_7.TOTAL_CORRECT.dropna(), bins=np.arange(2,42)-0.5)\n",
    "plt.xlabel('TOTAL_CORRECT')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "# Tending to the higher side for most patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_7 = df_7.groupby(['COMPLT_DATE']).COMPLT_DATE.count()\n",
    "print(events_series_7)\n",
    "# print(events_series.axes)\n",
    "# print(type(events_series.axes))\n",
    "# print(events_series.values)\n",
    "\n",
    "events_series_7.plot.bar()\n",
    "\n",
    "# The problem with doing dates is that it is too spread out. So we might need to map these to visits like the other\n",
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIP\n",
    "This is a questionnaire about gambling, buying, etc. It is a nerobehavioral questionnaire.\n",
    "\n",
    "1 means yes and 0 means no for answers to the questions. `non-motor08` (curated dataset) has each question listed. In the curated one there is a summary score, but in the full dataset there isn't. So we might need to encode an entire vector so each question holds value on its own as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"QUIP_Current_Short.csv\")\n",
    "df_8 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_8))\n",
    "df_8.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picked five questions randomly to see the values\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(df_8.TMGAMBLE.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('TMGAMBLE')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(df_8.CNTRLBUY.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('CNTRLBUY')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(df_8.TMEAT.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('TMEAT')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(df_8.TMTORACT.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('CNTRLDSM')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "# Most of them have a high number of No replies. Can't tell how much information we will get from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_8 = df_8.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_8)\n",
    "\n",
    "events_series_8.plot.bar()\n",
    "# Again the tapering trend down from V04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REM Sleep Behavior Questionnaire\n",
    "This is a Sleep Disorder Test. Very similar format to the QUIPCS in the previous section. This one has questions related to sleeping problems. Full forms for column headers in `non-motor09` file.\n",
    "\n",
    "0 stands of No. 1 for yes. `CNSOTHCM` column specifies any other disorders. No summary score in the full dataset so may be we have to do our aggregation or use the columns individually as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"REM_Sleep_Disorder_Questionnaire.csv\")\n",
    "df_9 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_9))\n",
    "df_9.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picked five questions randomly to see the values\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(df_9.DRMVIVID.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('DRMVIVID')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(df_9.DRMAGRAC.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('DRMAGRAC')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(df_9.SLPLMBMV.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('SLPLMBMV')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(df_9.MVAWAKEN.dropna(), bins=np.arange(0,3)-0.5)\n",
    "plt.xlabel('MVAWAKEN')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "# This one has a better split between 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_9 = df_9.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_9)\n",
    "# print(events_series.axes)\n",
    "# print(type(events_series.axes))\n",
    "# print(events_series.values)\n",
    "\n",
    "events_series_9.plot.bar()\n",
    "# This one goes down from V06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCOPA-AUT\n",
    "This is a autonomic test. It is for gauging the problems the patient is facing with respect to bodily functions. The questionnaire is answered with a scale 0-3 (0-Never, 1-Sometimes, 2-Regularly, 3-Often). `non-motor10` maps to this one.\n",
    "\n",
    "`SCAU23AT`, mentions any kind of drugs that might be taken by the patient. Similar thing for all columns suffixed with `AT`, `BT`, `CT` (so the columns ending it `T`). In each case it asks for medicines taken for the previous column. This may or may not be useful to us with the initial analysis. Might be useful later. Some are yes/no questions. And then they have to give the specific answer in the next column as mentioned above.\n",
    "\n",
    "We can again aggregate (sum) these scores. Lower score means better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"SCOPA-AUT.csv\")\n",
    "df_10 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_10))\n",
    "df_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs for some of the responses ignoring the one that were not answered by some patients\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(df_10.SCAU2.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('SCAU2')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(df_10.SCAU4.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('SCAU4')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(df_10.SCAU9.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('SCAU9')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(df_10.SCAU23.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('SCAU23')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_10 = df_10.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_10)\n",
    "\n",
    "events_series_10.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Fluency\n",
    "Neuropsychological Test. There are two derived scores for animal fluency. One is the T score and one is the scaled score. There are also total number of vegetables and fruits that were shown to participants. Can take these as features.\n",
    "\n",
    "The `T score` looks important. Details in `non-motor11` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Semantic_Fluency.csv\")\n",
    "df_11 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_11))\n",
    "df_11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_11.VLTFRUIT.dropna().min(),df_11.VLTFRUIT.dropna().max())\n",
    "\n",
    "# Graphs for the total scores\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(df_11.VLTANIM.dropna(), bins=np.arange(0,43)-0.5)\n",
    "plt.xlabel('VLTANIM')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(df_11.VLTVEG.dropna(), bins=np.arange(0,43)-0.5)\n",
    "plt.xlabel('VLTVEG')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(df_11.VLTFRUIT.dropna(), bins=np.arange(0,43)-0.5)\n",
    "plt.xlabel('VLTFRUIT')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_11 = df_11.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_11)\n",
    "\n",
    "events_series_11.plot.bar()\n",
    "# Not many responses from the few initial visits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-Trait Anxiety Inventory for Adults\n",
    "Neurobehavioral Test. The State-Trait Anxiety Inventory (STAI) is a psychological inventory based on a 4-point Likert scale and consists of 40 questions on a self-report basis.\n",
    "\n",
    "As a general observation, the curated dataset sums up values in a lot of sheets. We can also resort to that kind of aggregation. This sheet contains the 40 questions and their results. The questions are in the file `non-motor12`. Questions like I feel calm, I feel tensed. So we can't really sum the scores up because there are negative and positive questions. (1 is very less and 3 is very much)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"State-Trait_Anxiety_Inventory.csv\")\n",
    "df_12 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_12))\n",
    "df_12.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of scores for 4 randomly picked questions\n",
    "# First two are positive and the next two negative\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(df_12.STAIAD5.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('STAIAD5')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(df_12.STAIAD11.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('STAIAD11')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(df_12.STAIAD17.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('STAIAD17')\n",
    "plt.ylabel('Number of instances')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(df_12.STAIAD36.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('STAIAD36')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_12 = df_12.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_12)\n",
    "\n",
    "\n",
    "events_series_12.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbol Digit Modalities\n",
    "Neuropsychological Test. Similar to semantic fluency, there is a derived scaled score and T score. The derived scores seem to be important. Even the total score can be used as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(path, \"Symbol_Digit_Modalities.csv\")\n",
    "df_13 = pd.read_csv(file)\n",
    "print(\"Total number of rows are:\",len(df_13))\n",
    "df_13.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DVSD_SDM - Scaled score\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_13.DVSD_SDM.dropna())\n",
    "plt.xlabel('DVSD_SDM')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DVT_SDM - T-score\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_13.DVT_SDM.dropna())\n",
    "plt.xlabel('DVT_SDM')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDMTOTAL\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_13.SDMTOTAL.dropna())\n",
    "plt.xlabel('SDMTOTAL')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDMTVRSN\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_13.SDMTVRSN.dropna(), bins=np.arange(0,5)-0.5)\n",
    "plt.xlabel('SDMTVRSN')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients per visit graph\n",
    "events_series_13 = df_13.groupby(['EVENT_ID']).EVENT_ID.count()\n",
    "print(events_series_13)\n",
    "\n",
    "events_series_13.plot.bar()\n",
    "# Again very few results for the initial screening and such preliminary visits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here we will work on processing each file and writing all the information to a single DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_13 is sdmt dataframe\n",
    "df_13.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_13[['PATNO', 'EVENT_ID', 'INFODT', 'SDMTOTAL']] \n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.SDMTOTAL.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[df_processed.SDMTOTAL.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_12 - State Trait Anxiety Index (STAI)\n",
    "\n",
    "# Guidelines:\n",
    "# STAIAD1 - STAIAD40.  \n",
    "# Add values for the following questions:  \n",
    "# 3, 4, 6, 7, 9, 12, 13, 14, 17, 18, 22, 24, 25, 28, 29, 31, 32, 35, 37, 38, 40.  \n",
    "# Use reverse scoring for the remaining questions and add to the first score \n",
    "# (e.g., if value = 1, add 4 points to score; if value = 2, add 3 points to score, etc).\n",
    "df_12.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the final STAI\n",
    "add_stai = [3, 4, 6, 7, 9, 12, 13, 14, 17, 18, 22, 24, 25, 28, 29, 31, 32, 35, 37, 38, 40]\n",
    "stai_set = set()\n",
    "for v in add_stai:\n",
    "    s='STAIAD'+str(v)\n",
    "    stai_set.add(s)\n",
    "print(stai_set)\n",
    "\n",
    "rev_stai = list(range(41))\n",
    "for i in add_stai:\n",
    "    rev_stai.remove(i)\n",
    "print(rev_stai)\n",
    "\n",
    "stai_rev_set = set()\n",
    "for v in rev_stai:\n",
    "    if v==0:\n",
    "        continue\n",
    "    s='STAIAD'+str(v)\n",
    "    stai_rev_set.add(s)\n",
    "print(stai_rev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "df_12_columns = df_12.columns\n",
    "def stai_total(row):\n",
    "    # iterate over the keys\n",
    "    sum = 0\n",
    "    for key in df_12_columns:\n",
    "        if key in stai_set:\n",
    "            if math.isnan(row[key]):\n",
    "                return row[key] \n",
    "            sum+=int(row[key])\n",
    "        elif key in stai_rev_set:\n",
    "            if math.isnan(row[key]):\n",
    "                return row[key]\n",
    "            sum+=(5-int(row[key]))\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12['STAI_TOT'] = df_12.apply(stai_total,axis=1)\n",
    "df_12.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12.STAI_TOT.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_12[['PATNO','EVENT_ID','INFODT','STAI_TOT']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_11 - Semantic Fluency (SFT)\n",
    "\n",
    "# Guidelines\n",
    "# Sum of VLTANIM, VLTVEG, VLTFRUIT\n",
    "df_11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11['SFT_TOT'] = df_11[['VLTANIM','VLTVEG','VLTFRUIT']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_11[['PATNO','EVENT_ID','INFODT','SFT_TOT']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_10 - SCOPA-AUT\n",
    "\n",
    "# Guidelines\n",
    "# SCAU1 - SCAU25.  \n",
    "# For questions 1-21 (SCAU1 - SCAU21), add 3 points for each response of \"9\". \n",
    "# Otherwise, add the number of points in response.  \n",
    "# For questions 22-25 (SCAU22 - SCAU25), add 0 points for each respµonse of \"9\". \n",
    "# Otherwise, add the number of points in response.\n",
    "\n",
    "# Since there are different tests done for male/female. We will take nan=0µb\n",
    "df_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sa = list(range(1,26))\n",
    "sa_1 = set()\n",
    "sa_2 = set()\n",
    "for v in add_sa:\n",
    "    s='SCAU'+str(v)\n",
    "    if v in [22,23,24,25]:\n",
    "        sa_2.add(s)\n",
    "    else:\n",
    "        sa_1.add(s)\n",
    "print(sa_1)\n",
    "print(sa_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_columns = df_10.columns\n",
    "def scopa_total(row):\n",
    "    # iterate over the keys\n",
    "    sum = 0\n",
    "    for key in df_10_columns:\n",
    "        if key in sa_1:\n",
    "            if math.isnan(row[key]):\n",
    "                continue\n",
    "            if int(row[key])==9:\n",
    "                sum+=3\n",
    "            else:\n",
    "                sum+=int(row[key])\n",
    "        if key in sa_2:\n",
    "            if math.isnan(row[key]):\n",
    "                continue\n",
    "            if int(row[key])==9:\n",
    "                sum+=0\n",
    "            else:\n",
    "                sum+=int(row[key])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10['SCOPA_AUT_TOT'] = df_10.apply(scopa_total,axis=1)\n",
    "df_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_10[['PATNO','EVENT_ID','INFODT','SCOPA_AUT_TOT']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_9 - REM Sleep Behavior Questionnaire (REMSLEEP)\n",
    "\n",
    "# Guidelines\n",
    "# Add 1 point for each response of \"Yes\" (1) \n",
    "# to any of the following variables:  DRMVIVID, DRMAGRAC, DRMNOCTB, SLPLMBMV, SLPINJUR, \n",
    "# DRMVERBL, DRMFIGHT, DRMUMV, DRMOBJFL, MVAWAKEN, DRMREMEM, SLPDSTRB.  \n",
    "# Add 1 point if any of the following variables has a response of \"Yes\" (1):  \n",
    "# STROKE, HETRA, PARKISM, RLS, NARCLPSY, DEPRS, EPILEPSY, BRNINFM, CNSOTH.  \n",
    "# If any of the previous variables are missing, then RBD score is missing.  \n",
    "# Subjects with score >=5 are RBD Positive.  Subjects with score <5 are RBD Negative.\n",
    "\n",
    "# Also checked the curated file - If any of the variables are nan they don't really have a summary score\n",
    "# So just putting nan for those for now\n",
    "df_9.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_set = set([\"DRMVIVID\",\"DRMAGRAC\",\"DRMNOCTB\",\"SLPLMBMV\",\"SLPINJUR\",\n",
    "              \"DRMVERBL\",\"DRMFIGHT\",\"DRMUMV\",\"DRMOBJFL\",\"MVAWAKEN\",\n",
    "              \"DRMREMEM\",\"SLPDSTRB\",\"STROKE\",\"HETRA\",\"PARKISM\",\"RLS\",\n",
    "              \"NARCLPSY\",\"DEPRS\",\"EPILEPSY\",\"BRNINFM\",\"CNSOTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_sleep_total(row):\n",
    "    # iterate over the keys\n",
    "    sum = 0\n",
    "    for key in rs_set:\n",
    "        if math.isnan(row[key]):\n",
    "            return row[key] \n",
    "        sum+=int(row[key])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9['REMSLEEP_TOT'] = df_9.apply(rem_sleep_total,axis=1)\n",
    "df_9.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9.REMSLEEP_TOT.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_9[['PATNO','EVENT_ID','INFODT','REMSLEEP_TOT']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_8 - QUIPCS\n",
    "\n",
    "# Guidelines\n",
    "# For Sections A - D, add 1 point \n",
    "# if either question has a response of \"Yes\" (1):  \n",
    "# Section A:  CNTRLGMB, TMGAMBLE; Section B:  CNTRLSEX, TMSEX; \n",
    "# Section C:  CNTRLBUY, TMBUY; Section D:  CNTRLEAT, TMEAT.  \n",
    "# For Section E, add 1 point for each response of \"Yes\" (1):  \n",
    "# TMTORACT, TMTMTACT, TMTRWD.\n",
    "\n",
    "# A-D: Will be 1 if either or both have Yes. Otherwise 0\n",
    "# E: We will add across the three questions\n",
    "# So we will have multiple columns for this feature\n",
    "\n",
    "# NaN if anything for that particular question is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8['elderly'] = np.where((df['age']>=50), 1.0, 0.0)\n",
    "# df_8['QUIP_A'] = df_8.apply(lambda x: 1.0 if (x['CNTRLGMB']==1.0 or x['TMGAMBLE']==1.0) else 0.0, axis=1)\n",
    "# df_8.head(3)\n",
    "# Can't use this technique because we won't be able to account for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do all this to handle the NaNs :(\n",
    "def quip_A(x):\n",
    "    if math.isnan(x['CNTRLGMB']):\n",
    "        return x['CNTRLGMB']\n",
    "    if math.isnan(x['TMGAMBLE']):\n",
    "        return x['TMGAMBLE']\n",
    "    if x['CNTRLGMB']==1.0 or x['TMGAMBLE']==1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def quip_B(x):\n",
    "    if math.isnan(x['CNTRLSEX']):\n",
    "        return x['CNTRLSEX']\n",
    "    if math.isnan(x['TMSEX']):\n",
    "        return x['TMSEX']\n",
    "    if x['CNTRLSEX']==1.0 or x['TMSEX']==1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def quip_C(x):\n",
    "    if math.isnan(x['CNTRLBUY']):\n",
    "        return x['CNTRLBUY']\n",
    "    if math.isnan(x['TMBUY']):\n",
    "        return x['TMBUY']\n",
    "    if x['CNTRLBUY']==1.0 or x['TMBUY']==1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def quip_D(x):\n",
    "    if math.isnan(x['CNTRLEAT']):\n",
    "        return x['CNTRLEAT']\n",
    "    if math.isnan(x['TMEAT']):\n",
    "        return x['TMEAT']\n",
    "    if x['CNTRLEAT']==1.0 or x['TMEAT']==1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def quip_E(x):\n",
    "    sum=0\n",
    "    for col in [\"TMTORACT\",\"TMTMTACT\",\"TMTRWD\"]:\n",
    "        if math.isnan(x[col]):\n",
    "            return x[col]\n",
    "        if x[col]==1.0:\n",
    "            sum+=1.0\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8['QUIP_A'] = df_8.apply(quip_A,axis=1)\n",
    "df_8.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8['QUIP_B'] = df_8.apply(quip_B,axis=1)\n",
    "df_8['QUIP_C'] = df_8.apply(quip_C,axis=1)\n",
    "df_8['QUIP_D'] = df_8.apply(quip_D,axis=1)\n",
    "df_8['QUIP_E'] = df_8.apply(quip_E,axis=1)\n",
    "df_8.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_8[['PATNO','EVENT_ID','INFODT','QUIP_A','QUIP_B','QUIP_C','QUIP_D','QUIP_E']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_7 - Olfactory UPSIT\n",
    "# We will actually load the DF since df_7 has the more granular results\n",
    "file = os.path.join(path, \"University_of_Pennsylvania_Smell_ID_Test.csv\")\n",
    "df_upsit = pd.read_csv(file)\n",
    "\n",
    "# Guidelines\n",
    "# Sum of UPSITBK1 - UPSITBK4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_upsit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsit['UPSIT_TOT'] = df_upsit[['UPSITBK1','UPSITBK2','UPSITBK3','UPSITBK4']].sum(axis=1)\n",
    "df_upsit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_upsit[['PATNO','EVENT_ID','INFODT','UPSIT_TOT']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_6 - Montreal Cognitive Assessment (MoCA)\n",
    "\n",
    "# Guidelines\n",
    "# Unadjusted Score = sum of MCAALTTM, MCACUBE, MCACLCKC, MCACLCKN, MCACLCKH, \n",
    "# MCALION,  MCARHINO, MCACAMEL, MCAFDS, MCABDS, MCAVIGIL, MCASER7, MCASNTNC, \n",
    "# MCAVF, MCAABSTR, MCAREC1, MCAREC2, MCAREC3, MCAREC4, MCAREC5, MCADATE, MCAMONTH, \n",
    "# MCAYR, MCADAY, MCAPLACE, MCACTY.  If EDUCYRS <=12 \n",
    "# and Unadjusted Score < 30, add 1 more point to score.  \n",
    "# If EDUCYRS > 12, do not add any more points to score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the socio-eco table in\n",
    "file = os.path.join(path, \"Socio-Economics.csv\")\n",
    "df_se = pd.read_csv(file)\n",
    "df_se.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6_se = pd.merge(left=df_6, right=df_se[['PATNO','EDUCYRS']], \\\n",
    "                        on=['PATNO'])\n",
    "df_6_se.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6_se['Unadjusted_TOT'] = df_6_se[[\"MCAALTTM\",\"MCACUBE\",\"MCACLCKC\",\"MCACLCKN\",\\\n",
    "                                     \"MCACLCKH\",\"MCALION\",\"MCARHINO\",\"MCACAMEL\",\\\n",
    "                                     \"MCAFDS\",\"MCABDS\",\"MCAVIGIL\",\"MCASER7\",\"MCASNTNC\",\\\n",
    "                                     \"MCAVF\",\"MCAABSTR\",\"MCAREC1\",\"MCAREC2\",\"MCAREC3\",\\\n",
    "                                     \"MCAREC4\",\"MCAREC5\",\"MCADATE\",\"MCAMONTH\",\"MCAYR\",\\\n",
    "                                     \"MCADAY\",\"MCAPLACE\",\"MCACITY\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6_se.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6_se.Unadjusted_TOT.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.where(((df_6_se['Unadjusted_TOT']<30) & (df_6_se['EDUCYRS']<=12)), df_6_se['Unadjusted_TOT']+1, df_6_se['Unadjusted_TOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(a),len(df_6_se))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6_se['MoCA_score'] = a\n",
    "df_6_se.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6_se[((df_6_se['Unadjusted_TOT']<30) & (df_6_se['EDUCYRS']<=12))][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6_se.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_6_se[['PATNO','EVENT_ID','INFODT','MoCA_score']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_5 - Letter Number Sequencing (LNSPD)\n",
    "\n",
    "# Guidelines\n",
    "# Sum of LNS1A - LNS7C\n",
    "df_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5['LNS_TOT'] = df_5[[\"LNS1A\",\"LNS1B\",\"LNS1C\",\"LNS2A\",\"LNS2B\",\"LNS2C\",\"LNS3A\",\"LNS3B\",\n",
    "       \"LNS3C\",\"LNS4A\",\"LNS4B\",\"LNS4C\",\"LNS5A\",\"LNS5B\",\"LNS5C\",\"LNS6A\",\n",
    "       \"LNS6B\",\"LNS6C\",\"LNS7A\",\"LNS7B\",\"LNS7C\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_5[['PATNO','EVENT_ID','INFODT','LNS_TOT']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_4 - Hopkins Verbal Learning Test – Revised (HVLT)\n",
    "\n",
    "# Guidelines\n",
    "# HVLT Immediate/Total Recall\tSum of HVLTRT1 - HVLTRT3\n",
    "# HVLT Discrimination Recognition\tHVLTREC - (HVLTFPRL + HVLTFPUN)\n",
    "# HVLT Retention\tHVLTRDLY / max(HVLTRT2, HVLTRT3)\n",
    "df_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['HVLT_TOT_Recall'] = df_4[[\"HVLTRT1\",\"HVLTRT2\",\"HVLTRT3\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['HVLT_DCR_REC'] = df_4['HVLTREC'] - df_4['HVLTFPRL'] - df_4['HVLTFPUN']\n",
    "df_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['HVLTREC'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['HVLT_DCR_REC'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to apply for the other two columns in aggregation\n",
    "def hvlt_retention(x):\n",
    "    if math.isnan(x['HVLTRDLY']):\n",
    "        return x['HVLTRDLY']\n",
    "    if math.isnan(x['HVLTRT2']):\n",
    "        return x['HVLTRT2']\n",
    "    if math.isnan(x['HVLTRT3']):\n",
    "        return x['HVLTRT3']\n",
    "    return x['HVLTRDLY']/max(x['HVLTRT2'],x['HVLTRT3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['HVLT_RETENTION'] = df_4.apply(hvlt_retention,axis=1)\n",
    "df_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_4[['PATNO','EVENT_ID','INFODT','HVLT_TOT_Recall','HVLT_DCR_REC','HVLT_RETENTION']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_3 - Geriatric Depression Scale (GDS-15)\n",
    "\n",
    "# Guidelines\n",
    "# Add 1 point for each response of \"No\" (0) to any of the following variables:  \n",
    "# GDSSATIS, GDSGSPIR, GDSHAPPY, GDSALIVE, GDSENRGY. \n",
    "\n",
    "# Add 1 point for each response of \"Yes\" (1) to any of the following variables:  \n",
    "# GDSDROPD, GDSEMPTY, GDSBORED, GDSAFRAD, GDSHLPLS, GDSHOME, GDSMEMRY, GDSWRTLS, \n",
    "# GDSHOPLS, GDSBETER.  \n",
    "\n",
    "# Subjects with GDS >=5 are \"Depressed\".  Subjects with GDS <5 are \"Not Depressed\".\n",
    "df_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['GDS_NO_Count'] = 5.0 - df_3[[\"GDSSATIS\",\"GDSGSPIR\",\"GDSHAPPY\",\"GDSALIVE\",\"GDSENRGY\"]].sum(axis=1)\n",
    "df_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['GDS_YES_Count'] = df_3[[\"GDSDROPD\",\"GDSEMPTY\",\"GDSBORED\",\"GDSAFRAD\",\"GDSHLPLS\",\"GDSHOME\",\n",
    "                              \"GDSMEMRY\",\"GDSWRTLS\",\"GDSHOPLS\",\"GDSBETER\"]].sum(axis=1)\n",
    "df_3['GDS_TOT'] = df_3[['GDS_NO_Count','GDS_YES_Count']].sum(axis=1)\n",
    "df_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['GDS_Depressed'] = np.where((df_3['GDS_TOT']>=5), 1.0, 0.0) \n",
    "df_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_3[['PATNO','EVENT_ID','INFODT','GDS_TOT','GDS_Depressed']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_2 - Epworth Sleepiness Scale (ESS)\n",
    "\n",
    "# Guidelines\n",
    "# Sum of ESS1 - ESS8.  \n",
    "# Subjects with ESS <10 are \"Not Sleepy\".  \n",
    "# Subjects with ESS >=10 are \"Sleepy\".\n",
    "df_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 means sleepy and 0 means not sleepy\n",
    "df_2['ESS_TOT'] = df_2[[\"ESS1\",\"ESS2\",\"ESS3\",\"ESS4\",\"ESS5\",\"ESS6\",\"ESS7\",\"ESS8\"]].sum(axis=1)\n",
    "df_2['ESS_Sleepy'] = np.where((df_2['ESS_TOT']>=10), 1.0, 0.0)\n",
    "df_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_2[['PATNO','EVENT_ID','INFODT','ESS_TOT','ESS_Sleepy']], \\\n",
    "                        how='outer', on=['PATNO','EVENT_ID','INFODT'])\n",
    "df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the feature for df_1 - Benton Judgement of Line Orientation (BJLO)\n",
    "\n",
    "# Guidelines\n",
    "# Sum of BJLOT1 - BJLOT30\n",
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(text):\n",
    "    res=[]\n",
    "    for i in range(30):\n",
    "        res.append(text+str(i+1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_list('BJLOT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['BJLOT_TOT'] = df_1[['BJLOT1', 'BJLOT2', 'BJLOT3', 'BJLOT4', 'BJLOT5', 'BJLOT6', 'BJLOT7', \n",
    "                        'BJLOT8', 'BJLOT9', 'BJLOT10', 'BJLOT11', 'BJLOT12', 'BJLOT13', \n",
    "                        'BJLOT14', 'BJLOT15', 'BJLOT16', 'BJLOT17', 'BJLOT18', 'BJLOT19', \n",
    "                        'BJLOT20', 'BJLOT21', 'BJLOT22', 'BJLOT23', 'BJLOT24', 'BJLOT25', \n",
    "                        'BJLOT26', 'BJLOT27', 'BJLOT28', 'BJLOT29', 'BJLOT30']].sum(axis=1)\n",
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_1[['PATNO', 'EVENT_ID', 'INFODT', 'BJLOT_TOT']], \n",
    "                         how='outer', on=['PATNO','EVENT_ID','INFODT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datscn = pd.read_csv(path + 'DATSCAN_Analysis.csv')\n",
    "df_datscn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(left=df_processed, right=df_datscn, how='outer', on=['PATNO', 'EVENT_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are all done here!!! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv(\"non-motor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
